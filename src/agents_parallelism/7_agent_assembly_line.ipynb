{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce99ee17",
   "metadata": {},
   "source": [
    "### Agent Assembly Line\n",
    "\n",
    "What if the challenge isn’t the complexity of one task, but the sheer volume of a continuous stream of tasks?\n",
    "\n",
    "For many industrial applications, the most critical metric isn’t how fast you can process one item, but how many items you can process per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382aa0bf",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../../figures/agent_assembly_line.png\" width=\"1200\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467edf23",
   "metadata": {},
   "source": [
    "This pattern shifts our focus from minimizing latency to maximizing throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f52bbd9",
   "metadata": {},
   "source": [
    "Instead of one monolithic agent processing items one by one from start to finish, we break the process into a sequence of specialized stations. As soon as Station A finishes its job on Item 1, it passes the item to Station B and immediately starts working on Item 2. All stations work in parallel, but on different items in the stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46e91f",
   "metadata": {},
   "source": [
    "We will build a three-stage pipeline to process a batch of product reviews. Our goal is to demonstrate, through careful timing analysis, how this pipelined parallelism dramatically increases the number of reviews processed per second compared to a traditional, sequential approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "717cdace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29849b2a",
   "metadata": {},
   "source": [
    "First, we need to define the data structures that will represent a review as it moves through our assembly line, being progressively enriched at each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bad8cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "\n",
    "class TriageResult(BaseModel):\n",
    "    \"\"\"The structured output of the initial Triage station.\"\"\"\n",
    "    category: Literal[\"Feedback\", \"Bug Report\", \"Support Request\", \"Irrelevant\"] = Field(description=\"The category of the review.\")\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"The structured output of the Summarization station.\"\"\"\n",
    "    summary: str = Field(description=\"A one-sentence summary of the key feedback in the review.\")\n",
    "\n",
    "class ExtractedData(BaseModel):\n",
    "    \"\"\"The structured output of the Data Extraction station.\"\"\"\n",
    "    product_mentioned: str = Field(description=\"The specific product the review is about.\")\n",
    "    sentiment: Literal[\"Positive\", \"Negative\", \"Neutral\"] = Field(description=\"The overall sentiment of the review.\")\n",
    "    key_feature: str = Field(description=\"The main feature or aspect discussed in the review.\")\n",
    "\n",
    "class ProcessedReview(BaseModel):\n",
    "    \"\"\"The final, fully processed review object that accumulates data from all stations.\"\"\"\n",
    "    original_review: str\n",
    "    category: str\n",
    "    summary: Optional[str] = None\n",
    "    extracted_data: Optional[ExtractedData] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564b90c",
   "metadata": {},
   "source": [
    "These Pydantic models are the “standardized shipping containers” for our assembly line. The ProcessedReview object is the central data carrier. It is created at the first station (Triage) and then progressively enriched with a summary and extracted_data as it moves through the subsequent stations. This ensures a consistent data contract between each stage of our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d3c66",
   "metadata": {},
   "source": [
    "### Defining the Pipeline Agent Prompts\n",
    "Each agent in our assembly line gets a highly specialized prompt for its specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce1e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachneet/projects/agents_experimental/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "triage_parser = JsonOutputParser(\n",
    "    pydantic_object=TriageResult\n",
    ")\n",
    "\n",
    "triage_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Triage Specialist. Your job is to read a user review and categorize it into one of four categories: Feedback, Bug Report, Support Request, or Irrelevant.\\n\\n{format_instructions}\"),\n",
    "    (\"human\", \"Please categorize the following review:\\n\\n---\\n{review_text}\\n---\")\n",
    "]).partial(format_instructions=triage_parser.get_format_instructions())\n",
    "\n",
    "summarizer_parser = JsonOutputParser(\n",
    "    pydantic_object=Summary\n",
    ")\n",
    "\n",
    "summarizer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Summarization Specialist. Your job is to read a user review and write a clear, one-sentence summary of its main point.\\n\\n{format_instructions}\"),\n",
    "    (\"human\", \"Please summarize the following review:\\n\\n---\\n{review_text}\\n---\")\n",
    "]).partial(format_instructions=summarizer_parser.get_format_instructions())\n",
    "\n",
    "extractor_parser = JsonOutputParser(\n",
    "    pydantic_object=ExtractedData\n",
    ")\n",
    "\n",
    "extractor_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Data Extraction Specialist. Your job is to read a review summary and extract the product mentioned, the sentiment, and the key feature discussed.\\n\\n{format_instructions}\"),\n",
    "    (\"human\", \"Please extract structured data from the following summary:\\n\\n---\\n{summary_text}\\n---\")\n",
    "]).partial(format_instructions=extractor_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d2746",
   "metadata": {},
   "source": [
    "### Creating the Agent Chains\n",
    "We'll package our prompts and the structured-output LLM into reusable LangChain Expression Language (LCEL) chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "546a6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm = ChatHuggingFace(\n",
    "    llm=HuggingFaceEndpoint(\n",
    "        model=\"moonshotai/Kimi-K2-Instruct\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "13c36af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_chain = triage_prompt | llm | triage_parser\n",
    "summarizer_chain = summarizer_prompt | llm | summarizer_parser\n",
    "extractor_chain = extractor_prompt | llm | extractor_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa7b09",
   "metadata": {},
   "source": [
    "### Defining the Graph State\n",
    "The state will hold the initial batch of reviews and the final list of fully processed reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c82beb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class PipelineState(TypedDict):\n",
    "    # 'initial_reviews' holds the incoming batch of raw review strings.\n",
    "    initial_reviews: List[str]\n",
    "    # 'processed_reviews' is the list of ProcessedReview objects that are built up as they move through the pipeline.\n",
    "    processed_reviews: List[ProcessedReview]\n",
    "    performance_log: Annotated[List[str], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415a3d9",
   "metadata": {},
   "source": [
    "### Defining the Graph Nodes (The Assembly Stations)\n",
    "Each node represents a station on our assembly line. We will use Python's ThreadPoolExecutor to achieve true parallelism within each node, allowing each agent to process multiple items concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85780089",
   "metadata": {},
   "source": [
    "Now, we define the nodes for each “station” on our assembly line. The key implementation detail is that each node uses a ThreadPoolExecutor to process all the items assigned to its stage in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b748dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "MAX_WORKERS = 4  # This controls the degree of parallelism within each station.\n",
    "\n",
    "# Station 1: Triage Node\n",
    "def triage_node(state: PipelineState):\n",
    "    \"\"\"The first station: categorizes all initial reviews in parallel.\"\"\"\n",
    "    print(f\"--- [Station 1: Triage] Processing {len(state['initial_reviews'])} reviews... ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    triaged_reviews = []\n",
    "    # We use a ThreadPoolExecutor to make parallel LLM calls for each review.\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # We create a future for each review to be triaged.\n",
    "        future_to_review = {executor.submit(triage_chain.invoke, {\"review_text\": review}): review for review in state['initial_reviews']}\n",
    "        for future in tqdm(as_completed(future_to_review), total=len(state['initial_reviews']), desc=\"Triage Progress\"):\n",
    "            original_review = future_to_review[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                # We create the initial ProcessedReview object here.\n",
    "                triaged_reviews.append(ProcessedReview(original_review=original_review, category=result[\"category\"]))\n",
    "            except Exception as exc:\n",
    "                print(f'Review generated an exception: {exc}')\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"[Triage] Processed {len(state['initial_reviews'])} reviews in {execution_time:.2f}s.\"\n",
    "    print(log)\n",
    "    \n",
    "    # The output of this node is the initial list of processed reviews.\n",
    "    return {\"processed_reviews\": triaged_reviews, \"performance_log\": [log]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a04fb2",
   "metadata": {},
   "source": [
    "Instead of looping through the reviews one by one, it submits all of them to the triage_chain at once. The as_completed iterator then yields results as they finish, allowing us to build our list of triaged_reviews efficiently. This make sure that the time taken by this station is determined by the handful of slowest LLM calls, not the sum of all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10a658",
   "metadata": {},
   "source": [
    "The subsequent nodes, summarize_node and extract_data_node, follow the same parallel processing pattern. They first filter for the items they are responsible for and then process them concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station 2: Summarize Node\n",
    "def summarize_node(state: PipelineState):\n",
    "    \"\"\"The second station: filters for 'Feedback' reviews and summarizes them in parallel.\"\"\"\n",
    "    # This station only operates on reviews categorized as 'Feedback'.\n",
    "    feedback_reviews = [r for r in state['processed_reviews'] if r.category == \"Feedback\"]\n",
    "    if not feedback_reviews:\n",
    "        print(\"--- [Station 2: Summarizer] No feedback reviews to process. Skipping. ---\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"--- [Station 2: Summarizer] Processing {len(feedback_reviews)} feedback reviews... ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # We use a map to easily update the reviews in place.\n",
    "    review_map = {r.original_review: r for r in state['processed_reviews']}\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_review = {executor.submit(summarizer_chain.invoke, {\"review_text\": r.original_review}): r for r in feedback_reviews}\n",
    "        for future in tqdm(as_completed(future_to_review), total=len(feedback_reviews), desc=\"Summarizer Progress\"):\n",
    "            original_review_obj = future_to_review[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                # We find the original review object in our map and enrich it with the summary.\n",
    "                # but pydantic model is immutable\n",
    "                updated_review = original_review_obj.model_copy(update={\"summary\": result[\"summary\"]})\n",
    "                review_map[original_review_obj.original_review] = updated_review\n",
    "                # review_map[original_review_obj.original_review][\"summary\"] = result[\"summary\"]\n",
    "            except Exception as exc:\n",
    "                print(f'Review generated an exception: {exc}')\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"[Summarizer] Processed {len(feedback_reviews)} reviews in {execution_time:.2f}s.\"\n",
    "    print(log)\n",
    "    \n",
    "    # We return the full, updated list of reviews.\n",
    "    return {\"processed_reviews\": list(review_map.values()), \"performance_log\": [log]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9dcfa33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station 3: Extract Data Node\n",
    "def extract_data_node(state: PipelineState):\n",
    "    \"\"\"The final station: extracts structured data from summarized reviews in parallel.\"\"\"\n",
    "    # This station only operates on reviews that have a summary.\n",
    "    summarized_reviews = [r for r in state['processed_reviews'] if r.summary is not None]\n",
    "    if not summarized_reviews:\n",
    "        print(\"--- [Station 3: Extractor] No summarized reviews to process. Skipping. ---\")\n",
    "        return {}\n",
    "        \n",
    "    print(f\"--- [Station 3: Extractor] Processing {len(summarized_reviews)} summarized reviews... ---\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    review_map = {r.original_review: r for r in state['processed_reviews']}\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        future_to_review = {executor.submit(extractor_chain.invoke, {\"summary_text\": r.summary}): r for r in summarized_reviews}\n",
    "        for future in tqdm(as_completed(future_to_review), total=len(summarized_reviews), desc=\"Extractor Progress\"):\n",
    "            original_review_obj = future_to_review[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                # We enrich the review object one last time with the extracted data.\n",
    "                # review_map[original_review_obj.original_review][\"extracted_data\"] = result\n",
    "                extracted_data = ExtractedData(**result) if isinstance(result, dict) else result\n",
    "                updated_review = original_review_obj.model_copy(update={\"extracted_data\": extracted_data})\n",
    "                review_map[original_review_obj.original_review] = updated_review\n",
    "\n",
    "            except Exception as exc:\n",
    "                print(f'Review generated an exception: {exc}')\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    log = f\"[Extractor] Processed {len(summarized_reviews)} reviews in {execution_time:.2f}s.\"\n",
    "    print(log)\n",
    "    \n",
    "    return {\"processed_reviews\": list(review_map.values()), \"performance_log\": [log]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3210afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Initialize the graph.\n",
    "workflow = StateGraph(PipelineState)\n",
    "\n",
    "# Add the three stations as nodes.\n",
    "workflow.add_node(\"triage\", triage_node)\n",
    "workflow.add_node(\"summarize\", summarize_node)\n",
    "workflow.add_node(\"extract_data\", extract_data_node)\n",
    "\n",
    "# Define the linear flow of the assembly line.\n",
    "workflow.set_entry_point(\"triage\")\n",
    "workflow.add_edge(\"triage\", \"summarize\")\n",
    "workflow.add_edge(\"summarize\", \"extract_data\")\n",
    "workflow.add_edge(\"extract_data\", END)\n",
    "\n",
    "# Compile the graph.\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed666665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab16e85",
   "metadata": {},
   "source": [
    "### Running the Pipeline and Analyzing Throughput\n",
    "We'll create a batch of 10 sample reviews and run them through our assembly line. We'll pay close attention to the execution time of each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0340a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reviews = [\n",
    "    \"The Aura Smart Ring's battery life is incredible, easily lasts a week! Best sleep tracker I've ever used.\", # Feedback\n",
    "    \"My QuantumLeap processor arrived with a bent pin, and the box was crushed. I need a replacement ASAP.\", # Support Request\n",
    "    \"Love the new Smart Mug, but the app keeps crashing on my Android phone whenever I try to set a custom temperature.\", # Bug Report\n",
    "    \"The titanium finish on the Aura Ring feels so premium. It's lightweight and looks amazing.\", # Feedback\n",
    "    \"I think I was overcharged for my last order (A123). Can someone please check my invoice?\", # Support Request\n",
    "    \"The personalized energy suggestions from the Smart Mug are surprisingly accurate. A great feature!\", # Feedback\n",
    "    \"This is not a product review, I just wanted to say your website is very well designed.\", # Irrelevant\n",
    "    \"The QuantumLeap is fast, but it runs way too hot. The fan noise is a real problem under load.\", # Feedback\n",
    "    \"The app for the Aura Ring fails to sync my sleep data about half the time. I have to restart my phone to fix it.\", # Bug Report\n",
    "    \"I wish the Smart Mug came in more colors. A matte black option would be perfect.\", # Feedback\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a4807f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Station 1: Triage] Processing 10 reviews... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triage Progress: 100%|██████████| 10/10 [00:04<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Triage] Processed 10 reviews in 4.79s.\n",
      "--- [Station 2: Summarizer] Processing 6 feedback reviews... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizer Progress:  33%|███▎      | 2/6 [00:01<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_review=\"The titanium finish on the Aura Ring feels so premium. It's lightweight and looks amazing.\" category='Feedback' summary=None extracted_data=None\n",
      "{'summary': \"The reviewer loves the Aura Ring's premium titanium finish, noting its lightweight feel and attractive appearance.\"}\n",
      "original_review=\"The Aura Smart Ring's battery life is incredible, easily lasts a week! Best sleep tracker I've ever used.\" category='Feedback' summary=None extracted_data=None\n",
      "{'summary': 'The reviewer praises the Aura Smart Ring for its exceptional week-long battery life and excellent sleep tracking capabilities.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizer Progress:  67%|██████▋   | 4/6 [00:02<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_review='This is not a product review, I just wanted to say your website is very well designed.' category='Feedback' summary=None extracted_data=None\n",
      "{'summary': \"The reviewer praised the website's design rather than reviewing the product itself.\"}\n",
      "original_review='The QuantumLeap is fast, but it runs way too hot. The fan noise is a real problem under load.' category='Feedback' summary=None extracted_data=None\n",
      "{'summary': 'While the QuantumLeap is fast, its excessive heat and loud fan noise under load are major drawbacks.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizer Progress:  83%|████████▎ | 5/6 [00:03<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_review='The personalized energy suggestions from the Smart Mug are surprisingly accurate. A great feature!' category='Feedback' summary=None extracted_data=None\n",
      "{'summary': \"The reviewer praises the Smart Mug's personalized energy suggestions for being surprisingly accurate and a great feature.}\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizer Progress: 100%|██████████| 6/6 [00:04<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_review='I wish the Smart Mug came in more colors. A matte black option would be perfect.' category='Feedback' summary=None extracted_data=None\n",
      "{'summary': 'The reviewer wants the Smart Mug to be available in additional colors, specifically a matte black option.}'}\n",
      "[Summarizer] Processed 6 reviews in 4.13s.\n",
      "--- [Station 3: Extractor] Processing 6 summarized reviews... ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extractor Progress: 100%|██████████| 6/6 [00:04<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Extractor] Processed 6 reviews in 4.80s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"initial_reviews\": sample_reviews,\n",
    "    \"processed_reviews\": []\n",
    "}\n",
    "\n",
    "final_state = None\n",
    "for output in app.stream(inputs, stream_mode=\"values\"):\n",
    "    final_state = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2844de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "                FINAL PROCESSED DATA (Sample)\n",
      "============================================================\n",
      "{\n",
      "    \"original_review\": \"My QuantumLeap processor arrived with a bent pin, and the box was crushed. I need a replacement ASAP.\",\n",
      "    \"category\": \"Support Request\",\n",
      "    \"summary\": null,\n",
      "    \"extracted_data\": null\n",
      "}\n",
      "------------------------------------------------------------\n",
      "{\n",
      "    \"original_review\": \"The Aura Smart Ring's battery life is incredible, easily lasts a week! Best sleep tracker I've ever used.\",\n",
      "    \"category\": \"Feedback\",\n",
      "    \"summary\": \"The reviewer praises the Aura Smart Ring for its exceptional week-long battery life and excellent sleep tracking capabilities.\",\n",
      "    \"extracted_data\": {\n",
      "        \"product_mentioned\": \"Aura Smart Ring\",\n",
      "        \"sentiment\": \"Positive\",\n",
      "        \"key_feature\": \"week-long battery life and excellent sleep tracking capabilities\"\n",
      "    }\n",
      "}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"=\"*60)\n",
    "print(\"                FINAL PROCESSED DATA (Sample)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in [0, 1]: # Print a sample of two processed reviews\n",
    "    print(json.dumps(final_state['processed_reviews'][i], indent=4, default=lambda o: o.model_dump() if hasattr(o, 'dict') else o))\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44695f56",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad8fd41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.79 4.13 4.8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "logs = final_state[\"performance_log\"]\n",
    "triage_time = float(logs[0].content.rstrip(\"s.\").split(\" \")[-1])\n",
    "summarize_time = float(logs[1].content.rstrip(\"s.\").split(\" \")[-1])\n",
    "extract_time = float(logs[2].content.rstrip(\"s.\").split(\" \")[-1])\n",
    "\n",
    "\n",
    "print(triage_time, summarize_time, extract_time)\n",
    "num_reviews = len(final_state[\"processed_reviews\"])\n",
    "print(num_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "36b71342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "                      PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- Assembly Line (Pipelined) Workflow ---\n",
      "Total Time to Process 10 Reviews: 13.72 seconds\n",
      "Calculated Throughput: 0.73 reviews/second\n",
      "\n",
      "--- Monolithic (Sequential) Workflow (Simulated) ---\n",
      "Avg. Latency For One Review to Complete All Stages: 4.12 seconds\n",
      "Simulated Total Time to Process 10 Reviews: 41.16 seconds\n",
      "Simulated Throughput: 0.24 reviews/second\n",
      "\n",
      "============================================================\n",
      "                        CONCLUSION\n",
      "============================================================\n",
      "Throughput Increase: 200%\n"
     ]
    }
   ],
   "source": [
    "# The total time for our pipelined workflow is the sum of the time for each stage to process the entire batch.\n",
    "pipelined_total_time = triage_time + summarize_time + extract_time\n",
    "\n",
    "# Throughput is the total number of items processed divided by the total time.\n",
    "pipelined_throughput = num_reviews / pipelined_total_time\n",
    "\n",
    "# Now, we simulate a sequential, monolithic agent.\n",
    "# First, estimate the average time it takes for one item to pass through one stage.\n",
    "avg_time_per_stage_per_review = (triage_time + summarize_time + extract_time) / num_reviews\n",
    "\n",
    "# The total latency for a single review to be processed from start to finish is the time for all three stages.\n",
    "total_latency_per_review = avg_time_per_stage_per_review * 3\n",
    "\n",
    "# The total time for a sequential agent to process 10 reviews is 10 times the latency of one review.\n",
    "sequential_total_time = total_latency_per_review * num_reviews\n",
    "sequential_throughput = num_reviews / sequential_total_time\n",
    "\n",
    "# Calculate the percentage increase in throughput.\n",
    "throughput_increase = ((pipelined_throughput - sequential_throughput) / sequential_throughput) * 100\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"                      PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n--- Assembly Line (Pipelined) Workflow ---\")\n",
    "print(f\"Total Time to Process {num_reviews} Reviews: {pipelined_total_time:.2f} seconds\")\n",
    "print(f\"Calculated Throughput: {pipelined_throughput:.2f} reviews/second\\n\")\n",
    "print(\"--- Monolithic (Sequential) Workflow (Simulated) ---\")\n",
    "print(f\"Avg. Latency For One Review to Complete All Stages: {total_latency_per_review:.2f} seconds\")\n",
    "print(f\"Simulated Total Time to Process {num_reviews} Reviews: {sequential_total_time:.2f} seconds\")\n",
    "print(f\"Simulated Throughput: {sequential_throughput:.2f} reviews/second\\n\")\n",
    "print(\"=\"*60)\n",
    "print(\"                        CONCLUSION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Throughput Increase: {throughput_increase:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba0201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_experimental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
