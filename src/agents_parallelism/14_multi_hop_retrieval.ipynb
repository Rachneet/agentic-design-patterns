{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b88de28",
   "metadata": {},
   "source": [
    "### Multi-Hop Retrieval for Deep Reasoning\n",
    "\n",
    "Many complex user queries are not single questions at all, they are comparative, multi-step research tasks that require synthesizing information from multiple, disparate documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6accb",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../../figures/multi_hop_retrieval.png\" width=\"800\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d54764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8200793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachneet/projects/agents_experimental/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "llm = ChatHuggingFace(\n",
    "    llm=HuggingFaceEndpoint(\n",
    "        model=\"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0b9d49",
   "metadata": {},
   "source": [
    "The Parallel Multi-Hop Retrieval architecture is the solution. This pattern elevates the RAG system into a true research agent. The workflow mirrors how a human researcher would tackle a complex question:\n",
    "\n",
    "1. Decompose: A high-level Meta-Agent first analyzes the complex user query and breaks it down into several simpler, independent sub-questions.\n",
    "2. Scatter (Parallel Retrieval): Each sub-question is dispatched to its own dedicated Retrieval Agent. These agents run in parallel, each performing a standard RAG process to find the answer to its specific sub-question.\n",
    "3. Gather & Synthesize: The Meta-Agent collects the answers to all the sub-questions and then performs a final reasoning step to synthesize them into a single, comprehensive answer to the original complex query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e38262",
   "metadata": {},
   "source": [
    "We will build and compare a Simple RAG system with a Multi-Hop RAG system on a comparative question that is impossible to answer with a single retrieval. We will demonstrate that only the Multi-Hop system can successfully gather the necessary evidence to provide an accurate and insightful final answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f11d05",
   "metadata": {},
   "source": [
    "### Creating the Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b222db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nm/srw3ygl55jbgpddqwgysqjpm0000gn/T/ipykernel_34450/3486095030.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Base created with 4 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "kb_docs = [\n",
    "    Document(page_content=\"The QLeap-V4 processor is designed for maximum performance in data centers. It consumes 1200W of power under full load and uses a specialized liquid cooling system to manage heat.\", metadata={\"product\": \"QLeap-V4\"}),\n",
    "    Document(page_content=\"Key features of the QLeap-V4 include 128 tensor cores and a 3nm process node, making it ideal for large-scale AI model training.\", metadata={\"product\": \"QLeap-V4\"}),\n",
    "    Document(page_content=\"The Eco-AI-M2 chip is designed for edge computing and mobile devices. Its primary feature is low power consumption, drawing only 15W under full load.\", metadata={\"product\": \"Eco-AI-M2\"}),\n",
    "    Document(page_content=\"Built on a 7nm process node, the Eco-AI-M2 has 8 specialized neural cores, making it perfect for real-time inference on devices like drones and smart cameras.\", metadata={\"product\": \"Eco-AI-M2\"})\n",
    "]\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(kb_docs, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "print(f\"Knowledge Base created with {len(kb_docs)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d4f3b",
   "metadata": {},
   "source": [
    "### Structured Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20395ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class SubQuestions(BaseModel):\n",
    "    \"\"\"A list of independent sub-questions to be answered in parallel.\"\"\"\n",
    "    questions: List[str] = Field(description=\"A list of 2-3 simple, self-contained questions that, when answered together, will fully address the original complex query.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393d2d3",
   "metadata": {},
   "source": [
    "### The Baseline - A Simple RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ebad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generator_prompt_template = (\n",
    "    \"You are an expert AI hardware analyst. Answer the user's question with high accuracy, based *only* on the following context. \"\n",
    "    \"Synthesize the information into a clear, comparative answer.\\n\\n\"\n",
    "    \"Context:\\n{context}\\n\\nQuestion: {question}\"\n",
    ")\n",
    "generator_prompt = ChatPromptTemplate.from_template(generator_prompt_template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "simple_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generator_prompt\n",
    "    | llm\n",
    "| StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100e957",
   "metadata": {},
   "source": [
    "### Building the Multi-Hop RAG Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a7aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Annotated\n",
    "from langchain_core.documents import Document\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "class MultiHopRAGState(TypedDict):\n",
    "    original_question: str\n",
    "    sub_questions: List[str]\n",
    "    # The dict will store the answer to each sub-question\n",
    "    sub_question_answers: Annotated[Dict[str, str], lambda a, b: {**a, **b}]\n",
    "    final_answer: str\n",
    "\n",
    "# Node 1: Decomposer (The Meta-Agent)\n",
    "decomposer_parser = JsonOutputParser(\n",
    "    pydantic_object=SubQuestions\n",
    ")\n",
    "decomposer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a query decomposition expert. Your job is to break down a complex question into simple, independent sub-questions that can be answered by a retrieval system. \"\n",
    "    \"Do not try to answer the questions yourself.\\n\\n{format_instructions}\\n\\n\"\n",
    "    \"Question: {question}\",\n",
    ").partial(format_instructions=decomposer_parser.get_format_instructions())\n",
    "decomposer_chain = decomposer_prompt | llm | decomposer_parser\n",
    "\n",
    "def decomposer_node(state: MultiHopRAGState):\n",
    "    print(\"--- [Meta-Agent] Decomposing complex question... ---\")\n",
    "    result = decomposer_chain.invoke({\"question\": state['original_question']})\n",
    "    print(f\"--- [Meta-Agent] Generated {len(result[\"questions\"])} sub-questions. ---\")\n",
    "    return {\"sub_questions\": result[\"questions\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c73b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 2: Parallel Retrieval Agents\n",
    "# This is a self-contained RAG chain that answers a single, simple question.\n",
    "sub_question_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | generator_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "def retrieval_agent_node(state: MultiHopRAGState):\n",
    "    \"\"\"Runs a RAG process for each sub-question in parallel.\"\"\"\n",
    "    print(f\"--- [Retrieval Agents] Answering {len(state['sub_questions'])} sub-questions in parallel... ---\")\n",
    "    \n",
    "    answers = {}\n",
    "    with ThreadPoolExecutor(max_workers=len(state['sub_questions'])) as executor:\n",
    "        # Map each sub-question to the RAG chain\n",
    "        future_to_question = {executor.submit(sub_question_rag_chain.invoke, q): q for q in state['sub_questions']}\n",
    "        for future in as_completed(future_to_question):\n",
    "            question = future_to_question[future]\n",
    "            try:\n",
    "                answer = future.result()\n",
    "                answers[question] = answer\n",
    "                print(f\"  - Answer found for sub-question: '{question}'\")\n",
    "            except Exception as e:\n",
    "                answers[question] = f\"Error answering question: {e}\"\n",
    "\n",
    "    return {\"sub_question_answers\": answers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32f1dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3: Synthesizer (The Meta-Agent's final step)\n",
    "synthesizer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"You are a synthesis expert. Your job is to combine the answers to several sub-questions into a single, cohesive, and comprehensive answer to the user's original complex question.\\n\\n\"\n",
    "    \"Original Question: {original_question}\\n\\n\"\n",
    "    \"Sub-Question Answers:\\n{sub_question_answers}\"\n",
    ")\n",
    "synthesizer_chain = synthesizer_prompt | llm | StrOutputParser()\n",
    "\n",
    "def synthesizer_node(state: MultiHopRAGState):\n",
    "    print(\"--- [Meta-Agent] Synthesizing final answer... ---\")\n",
    "    \n",
    "    sub_answers_str = \"\\n\".join([f\"- Q: {q}\\n- A: {a}\" for q, a in state['sub_question_answers'].items()])\n",
    "    \n",
    "    final_answer = synthesizer_chain.invoke({\n",
    "        \"original_question\": state['original_question'],\n",
    "        \"sub_question_answers\": sub_answers_str\n",
    "    })\n",
    "    return {\"final_answer\": final_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1d14379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "workflow = StateGraph(MultiHopRAGState)\n",
    "\n",
    "workflow.add_node(\"decompose\", decomposer_node)\n",
    "workflow.add_node(\"retrieve_in_parallel\", retrieval_agent_node)\n",
    "workflow.add_node(\"synthesize\", synthesizer_node)\n",
    "\n",
    "workflow.set_entry_point(\"decompose\")\n",
    "workflow.add_edge(\"decompose\", \"retrieve_in_parallel\")\n",
    "workflow.add_edge(\"retrieve_in_parallel\", \"synthesize\")\n",
    "workflow.add_edge(\"synthesize\", END)\n",
    "\n",
    "multi_hop_rag_app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "634e5515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(multi_hop_rag_app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33992f",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4191436",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Compare the QLeap-V4 and the Eco-AI-M2, focusing on their target use case and power consumption.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e5d5e",
   "metadata": {},
   "source": [
    "### Simple RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1194fdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "                  SIMPLE RAG SYSTEM OUTPUT\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context:\n",
      "The QLeap-V4 processor is designed for maximum performance in data centers. It consumes 1200W of power under full load and uses a specialized liquid cooling system to manage heat.\n",
      "\n",
      "The Eco-AI-M2 chip is designed for edge computing and mobile devices. Its primary feature is low power consumption, drawing only 15W under full load.\n",
      "\n",
      "Final Answer:\n",
      "The QLeap-V4 and the Eco-AI-M2 are optimized for different use cases and exhibit significant differences in power consumption.\n",
      "\n",
      "The QLeap-V4 is designed for data center environments, where high computational performance is critical. It consumes 1200W under full load, reflecting its capability to handle intensive workloads typical of large-scale data center operations. Its power demand is justified by its performance-oriented design and reliance on a specialized liquid cooling system to manage heat.\n",
      "\n",
      "In contrast, the Eco-AI-M2 is tailored for edge computing and mobile devices, where energy efficiency and battery life are paramount. It draws only 15W under full load, making it ideal for portable and energy-constrained applications.\n",
      "\n",
      "In summary:  \n",
      "- Target use case: QLeap-V4 for data centers; Eco-AI-M2 for edge and mobile devices.  \n",
      "- Power consumption: QLeap-V4 (1200W) vs. Eco-AI-M2 (15W).  \n",
      "The QLeap-V4 prioritizes raw performance at the cost of high power use, while the Eco-AI-M2 emphasizes energy efficiency for low-power, portable applications.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"                  SIMPLE RAG SYSTEM OUTPUT\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# We intercept the retrieval step to inspect the documents\n",
    "simple_retrieved_docs = retriever.invoke(user_query)\n",
    "\n",
    "print(\"Retrieved Context:\")\n",
    "print(format_docs(simple_retrieved_docs) + \"\\n\")\n",
    "\n",
    "simple_answer = simple_rag_chain.invoke(user_query)\n",
    "print(\"Final Answer:\")\n",
    "print(simple_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b9a593",
   "metadata": {},
   "source": [
    "### Running the Multi-Hop RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eaf99e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Meta-Agent] Decomposing complex question... ---\n",
      "--- [Meta-Agent] Generated 4 sub-questions. ---\n",
      "--- [Retrieval Agents] Answering 4 sub-questions in parallel... ---\n",
      "  - Answer found for sub-question: 'What is the power consumption of the QLeap-V4?'\n",
      "  - Answer found for sub-question: 'What is the power consumption of the Eco-AI-M2?'\n",
      "  - Answer found for sub-question: 'What is the target use case for the QLeap-V4?'\n",
      "  - Answer found for sub-question: 'What is the target use case for the Eco-AI-M2?'\n",
      "--- [Meta-Agent] Synthesizing final answer... ---\n",
      "============================================================\n",
      "                 MULTI-HOP RAG SYSTEM OUTPUT\n",
      "============================================================\n",
      "\n",
      "--- Sub-Question Answers ---\n",
      "1. Q: What is the power consumption of the QLeap-V4?\n",
      "   A: The power consumption of the QLeap-V4 is 1200W under full load.\n",
      "2. Q: What is the power consumption of the Eco-AI-M2?\n",
      "   A: The power consumption of the Eco-AI-M2 is 15W under full load.\n",
      "3. Q: What is the target use case for the QLeap-V4?\n",
      "   A: The target use case for the QLeap-V4 is large-scale AI model training in data centers. Its design, including 128 tensor cores and a 3nm process node, prioritizes maximum performance for computationally intensive AI workloads.\n",
      "4. Q: What is the target use case for the Eco-AI-M2?\n",
      "   A: The target use case for the Eco-AI-M2 is edge computing and mobile devices, particularly applications requiring real-time inference on power-constrained devices such as drones and smart cameras. Its low power consumption (15W under full load) and 8 specialized neural cores make it well-suited for on-device AI workloads where efficiency and responsiveness are critical.\n",
      "\n",
      "--- Final Synthesized Answer ---\n",
      "The QLeap-V4 and the Eco-AI-M2 are designed for fundamentally different applications, reflecting their distinct architectural priorities and performance profiles. The QLeap-V4 is targeted at large-scale AI model training in data centers, where computational power and performance are paramount. Equipped with 128 tensor cores and built on a 3nm process node, it is optimized to handle computationally intensive workloads such as training massive deep learning models. However, this high-performance capability comes at a significant power cost: it consumes 1200W under full load, making it suitable only for well-ventilated, energy-efficient data center environments with robust power infrastructure.\n",
      "\n",
      "In contrast, the Eco-AI-M2 is designed for edge computing and deployment in mobile and embedded devices, such as drones and smart cameras. Its primary goal is energy efficiency and low latency for real-time AI inference. With a power consumption of just 15W under full load and 8 specialized neural cores, the Eco-AI-M2 excels in power-constrained settings where battery life, responsiveness, and continuous operation are critical. This makes it ideal for edge applications that require on-device AI processing without relying on cloud connectivity.\n",
      "\n",
      "In summary, the QLeap-V4 prioritizes peak performance for data center AI training at the expense of high power consumption, while the Eco-AI-M2 emphasizes ultra-low power use and real-time inference for efficient, on-device AI operations. Their differing use cases reflect a clear trade-off between computational throughput and energy efficiency, tailored to the demands of centralized cloud computing versus decentralized, mobility-focused environments.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"original_question\": user_query}\n",
    "multi_hop_result = None\n",
    "for output in multi_hop_rag_app.stream(inputs, stream_mode=\"values\"):\n",
    "    multi_hop_result = output\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"                 MULTI-HOP RAG SYSTEM OUTPUT\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"--- Sub-Question Answers ---\")\n",
    "for i, (q, a) in enumerate(multi_hop_result['sub_question_answers'].items()):\n",
    "    print(f\"{i+1}. Q: {q}\")\n",
    "    print(f\"   A: {a}\")\n",
    "\n",
    "print(\"\\n--- Final Synthesized Answer ---\")\n",
    "print(multi_hop_result['final_answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_experimental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
