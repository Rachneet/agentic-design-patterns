{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359148fb",
   "metadata": {},
   "source": [
    "# Essay Writer Agent\n",
    "\n",
    "An expert writer tasked with writing a an essay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b95ff",
   "metadata": {},
   "source": [
    "Workdflow:\n",
    "\n",
    "Plan -> Research plan -> Generate -> Either Finish or Reflect -> Reflect critique -> Generate -> Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9cf786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachneet/projects/agents_experimental/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a04b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen3-Next-80B-A3B-Instruct\",\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0,\n",
    "    provider=\"together\"\n",
    ")\n",
    "\n",
    "chat_model = ChatHuggingFace(\n",
    "    llm=llm,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d3c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "conn = sqlite3.connect(\"essay_agent.db\", check_same_thread=False)\n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f96418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055e118",
   "metadata": {},
   "source": [
    "## Agent Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c00442",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39da5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac353db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9044fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6984d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dddb9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0acad6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa5f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = chat_model.invoke(messages)\n",
    "    print(\"Plan Response:\", response)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdfe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = chat_model.bind_tools(tools=[Queries]).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    \n",
    "    # Extract tool calls from the AIMessage\n",
    "    if queries.tool_calls:\n",
    "        for tool_call in queries.tool_calls:\n",
    "            # Parse the arguments to get the Queries object\n",
    "            query_list = tool_call['args']['queries']  # Adjust based on your Queries schema\n",
    "            \n",
    "            for q in query_list:\n",
    "                response = tavily.search(query=q, max_results=2)\n",
    "                for r in response['results']:\n",
    "                    content.append(r['content'])\n",
    "    \n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1225c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = chat_model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1c100f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = chat_model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbded00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = chat_model.bind_tools(tools=[Queries]).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    # Extract tool calls from the AIMessage\n",
    "    if queries.tool_calls:\n",
    "        for tool_call in queries.tool_calls:\n",
    "            # Parse the arguments to get the Queries object\n",
    "            query_list = tool_call['args']['queries']  # Adjust based on your Queries schema\n",
    "            \n",
    "            for q in query_list:\n",
    "                response = tavily.search(query=q, max_results=2)\n",
    "                for r in response['results']:\n",
    "                    content.append(r['content'])\n",
    "    \n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79531df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb9a9969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15c0e4050>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner\", research_plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "78bf0b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15c0e4050>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "460e1089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x15c0e4050>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b63985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43140241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e217fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. You might think of LangSmith as LangChain's counterpart, but it takes things further by focusing on managing, debugging, and orchestrating AI and ML models. LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. In short, while LangChain excels at managing and scaling model workflows, LangSmith is designed for when you need deep visibility and control over large, complex AI systems in production. If you're debugging complex AI models or managing large-scale workflows with multiple moving parts, LangSmith's advanced debugging and orchestration features will be indispensable.\", 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.']}}\n",
      "{'research_plan': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. You might think of LangSmith as LangChain's counterpart, but it takes things further by focusing on managing, debugging, and orchestrating AI and ML models. LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. In short, while LangChain excels at managing and scaling model workflows, LangSmith is designed for when you need deep visibility and control over large, complex AI systems in production. If you're debugging complex AI models or managing large-scale workflows with multiple moving parts, LangSmith's advanced debugging and orchestration features will be indispensable.\", 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', '### LangChain: Building with Chains, Tools, and Prompts LangChain wraps this behavior into its agent classes, so you don’t have to build it from scratch, **but you still need to define the tools, prompt logic, and output parsers yourself**. Setting `verbose=True` as shown above shows the full prompt that LangChain constructs for the LLM, including tool names, usage instructions, and expected output format. And because every LLM evaluation is tied to a specific versioned prompt and function, you can trace patterns across iterations and app versions — something that’s harder to do in systems like LangSmith, where evaluations are often tied to static datasets or separated from prompt logic.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', '[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Da18cff9b31f0&operation=register&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=---header_actions--a18cff9b31f0---------------------post_audio_button------------------) [What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=---post_responses--a18cff9b31f0---------------------respond_sidebar------------------) [![Image 11: Ajay Verma](https://miro.medium.com/v2/resize:fill:20:20/1*bcWYlekM-dWdWA5Tp2whcg.jpeg)](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [Ajay Verma](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) While Generative AI has…](https://medium.com/@ajayverma23/from-ai-agents-to-agentic-ai-to-mcp-servers-revolutionizing-automation-and-decision-making-a5fb8ab710f4?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [35 3](https://medium.com/@ajayverma23/from-ai-agents-to-agentic-ai-to-mcp-servers-revolutionizing-automation-and-decision-making-a5fb8ab710f4?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 13: GoPenAI](https://miro.medium.com/v2/resize:fill:20:20/1*LUSEiP1BHPkkmH75e8eg_A.png)](https://blog.gopenai.com/?source=post_page---author_recirc--a18cff9b31f0----1---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 15: GoPenAI](https://miro.medium.com/v2/resize:fill:20:20/1*LUSEiP1BHPkkmH75e8eg_A.png)](https://blog.gopenai.com/?source=post_page---author_recirc--a18cff9b31f0----2---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 17: Ajay Verma](https://miro.medium.com/v2/resize:fill:20:20/1*bcWYlekM-dWdWA5Tp2whcg.jpeg)](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [Ajay Verma](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) Two of the most prominent frameworks for…](https://medium.com/@ajayverma23/google-adk-vs-langgraph-a-comprehensive-blog-guide-eaceeb89d583?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [](https://medium.com/@ajayverma23/google-adk-vs-langgraph-a-comprehensive-blog-guide-eaceeb89d583?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 19: James Tang](https://miro.medium.com/v2/resize:fill:20:20/1*vnM7rwphFHLaxFPoE4rokw.png)](https://medium.com/@jamestang?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [James Tang](https://medium.com/@jamestang?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [](https://medium.com/@jamestang/exploring-rag-retrieval-augmented-generation-with-python-1645ad66f765?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 21: Mothish](https://miro.medium.com/v2/resize:fill:20:20/1*FUlvx_kntiJu6H6iQklXaA.jpeg)](https://mothishdeenadayalan.medium.com/?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Mothish](https://mothishdeenadayalan.medium.com/?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) But here’s what nobody tells you upfront…](https://mothishdeenadayalan.medium.com/langchain-vs-langgraph-the-beginners-guide-15daa489c018?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [50](https://mothishdeenadayalan.medium.com/langchain-vs-langgraph-the-beginners-guide-15daa489c018?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 23: Towards AI](https://miro.medium.com/v2/resize:fill:20:20/1*JyIThO-cLjlChQLb6kSlVQ.png)](https://pub.towardsai.net/?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Sayanteka Chakraborty](https://medium.com/@sd24chakraborty?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 25: aakash](https://miro.medium.com/v2/resize:fill:20:20/1*wkAmsUU1Zshd-u9CxHxUxw.jpeg)](https://medium.com/@aakash_7?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [aakash](https://medium.com/@aakash_7?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [14 2](https://medium.com/@aakash_7/the-future-of-ai-prompting-5-context-levels-fc12d6fdf862?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 27: Artificial Intelligence in Plain English](https://miro.medium.com/v2/resize:fill:20:20/1*9zAmnK08gUCmZX7q0McVKw@2x.png)](https://ai.plainenglish.io/?source=post_page---read_next_recirc--a18cff9b31f0----2---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Piyush Agnihotri](https://medium.com/@piyushagni5?source=post_page---read_next_recirc--a18cff9b31f0----2---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc2c4578c836a&operation=register&redirect=https%3A%2F%2Fai.plainenglish.io%2Fbuilding-agentic-rag-with-langgraph-mastering-adaptive-rag-for-production-c2c4578c836a&source=---read_next_recirc--a18cff9b31f0----2-----------------bookmark_preview----bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 29: Sanjit Khasnobis](https://miro.medium.com/v2/resize:fill:20:20/1*gOxwJEpFDszNFJT_VrzO_g.jpeg)](https://medium.com/@khasnobis.sanjit890?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Sanjit Khasnobis](https://medium.com/@khasnobis.sanjit890?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Difference between lang Chain and Lang Graph: Land of Agentic AI ---------------------------------------------------------------- ### I always enjoy exploring both sides of my skill set — as an Engineer and as an Architect.](https://medium.com/@khasnobis.sanjit890/difference-between-lang-chain-and-lang-graph-land-of-agentic-ai-ff373240fa07?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [1](https://medium.com/@khasnobis.sanjit890/difference-between-lang-chain-and-lang-graph-land-of-agentic-ai-ff373240fa07?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------)']}}\n",
      "{'generate': {'draft': '**The Difference Between LangChain and LangSmith: Building vs. Observing LLM Applications**\\n\\nLangChain and LangSmith are two complementary tools in the modern large language model (LLM) development stack, each serving a distinct but interconnected purpose. LangChain is an open-source framework designed to help developers build LLM-powered applications by providing modular components—such as prompts, chains, agents, tools, and memory—that streamline the creation of complex workflows. It abstracts away much of the boilerplate code needed to connect LLMs with external data sources, APIs, and custom logic, enabling rapid prototyping and deployment. Developers use LangChain to define how an AI system should behave: what prompts to use, which tools to invoke, and how to chain responses together. In contrast, LangSmith is not a framework for building applications but a managed platform for observing, debugging, and optimizing them. It provides a web-based UI, detailed tracing of LLM calls, evaluation metrics, and performance analytics, allowing teams to understand how their models behave in real-world scenarios.\\n\\nWhile LangChain focuses on the “how” of application development, LangSmith focuses on the “what” and “why” of model performance. LangChain gives you the building blocks—you define the agent’s logic, select the LLM, and wire up tools like search or databases. But once deployed, you’re left to manually log outputs, test edge cases, or build custom evaluation scripts to measure accuracy, latency, or hallucination rates. LangSmith fills this gap by automatically capturing every step of an LLM’s execution—prompt inputs, intermediate reasoning, tool calls, and final responses—then visualizing them in an intuitive timeline. This level of observability is critical for production-grade systems, where subtle failures (e.g., a tool returning malformed JSON or a prompt causing unintended bias) can cascade into user-facing issues. LangSmith also enables A/B testing of prompts and models, making it easy to quantify improvements across iterations.\\n\\nAnother key distinction lies in their deployment and access models. LangChain is entirely open-source and free to use, with no vendor lock-in, making it ideal for startups, researchers, and developers who want full control over their infrastructure. You can run LangChain applications locally, on-premises, or across any cloud provider without cost. LangSmith, on the other hand, operates as a freemium SaaS platform. While it offers a free tier for small-scale use, its advanced features—such as team collaboration, automated evaluation suites, and cross-platform monitoring—are only available through paid plans. This makes LangSmith particularly valuable for enterprises and teams managing complex, multi-model pipelines that span cloud and on-prem environments. Its ability to unify monitoring across diverse deployments—whether using OpenAI, Anthropic, or self-hosted LLMs—gives organizations a single pane of glass for managing AI reliability at scale.\\n\\nThe synergy between LangChain and LangSmith is where their true power emerges. Most production teams use LangChain to construct their LLM workflows and then integrate LangSmith’s SDK to automatically log and evaluate those workflows in real time. For example, a developer might use LangChain to build a customer service agent that retrieves documents, generates responses, and validates answers against a knowledge base. With LangSmith, they can then track which prompts lead to the most accurate answers, identify when the agent hallucinates, and even rerun failed executions with modified parameters—all without touching the core application code. This combination transforms development from a trial-and-error process into a data-driven discipline, where every change is measurable and every failure is traceable.\\n\\nIn summary, LangChain is the engine that powers LLM applications, while LangSmith is the dashboard that keeps them running smoothly. If you’re a developer building your first AI chatbot or research prototype, LangChain alone may be sufficient. But if you’re responsible for deploying, scaling, and maintaining AI systems in production—especially those involving multiple models, dynamic workflows, or cross-platform deployments—LangSmith becomes indispensable. Together, they form a complete lifecycle solution: LangChain for creation, LangSmith for confidence. Choosing between them isn’t an either/or decision; it’s about understanding when to build and when to observe. For serious LLM applications, the most successful teams use both.', 'revision_number': 2}}\n",
      "{'reflect': {'critique': 'Your essay, **“The Difference Between LangChain and LangSmith: Building vs. Observing LLM Applications,”** is already **excellent**—clear, well-structured, technically accurate, and written with a mature, professional tone. It effectively distinguishes the roles of both tools, explains their synergy, and contextualizes them within real-world development workflows. Below is a detailed **grading critique and set of recommendations** to elevate it from *excellent* to *outstanding*—ideal for publication, academic submission, or professional presentation.\\n\\n---\\n\\n### ✅ **Strengths (What You Did Brilliantly)**\\n\\n| Category | Assessment |\\n|--------|------------|\\n| **Clarity & Structure** | Exceptional. The essay flows logically: introduction → contrast → deployment models → synergy → conclusion. Each paragraph has a clear topic sentence and builds on the last. |\\n| **Technical Accuracy** | Flawless. You correctly identify LangChain as a *development framework* and LangSmith as an *observability platform*. No misrepresentations of functionality. |\\n| **Depth of Insight** | Strong. You go beyond surface-level definitions to explain *why* observability matters (e.g., hallucinations, malformed JSON, bias), and how LangSmith enables data-driven iteration. |\\n| **Audience Awareness** | Perfectly targeted. You speak to both beginners (“first AI chatbot”) and enterprise teams (“multi-model pipelines”), making the piece broadly valuable. |\\n| **Tone & Style** | Professional, concise, and engaging. No jargon without explanation. Uses metaphors (“engine vs. dashboard”) effectively. |\\n\\n---\\n\\n### 🔧 **Recommendations for Improvement**\\n\\n#### 1. **Increase Depth in the “Why Observability Matters” Section**  \\n**Current state**: You mention hallucinations, malformed JSON, and bias—but briefly.  \\n**Recommendation**: Add **one concrete example** of a real-world failure that LangSmith would have caught.  \\n> *Example addition*:  \\n> *“For instance, a financial services startup using LangChain to generate loan eligibility summaries inadvertently trained their prompt to over-rely on keywords like ‘stable income’—leading LangSmith to detect a 37% increase in false rejections for gig workers. By analyzing trace logs, the team discovered the model was ignoring income variability patterns in the retrieved documents. Without LangSmith’s granular tracing, this systemic bias would have gone unnoticed until regulatory complaints arose.”*\\n\\n✅ **Why this helps**: Transforms abstract concerns into tangible business risk, strengthening your argument for LangSmith’s necessity in production.\\n\\n---\\n\\n#### 2. **Clarify the “What” vs. “Why” Distinction**  \\n**Current statement**:  \\n> “LangChain focuses on the ‘how’ of application development, while LangSmith focuses on the ‘what’ and ‘why’ of model performance.”\\n\\nThis is clever—but slightly ambiguous. “What” and “why” are vague.  \\n**Recommendation**: Reframe for precision:  \\n> *“LangChain focuses on the ‘how’—the logic, structure, and orchestration of LLM workflows. LangSmith focuses on the ‘what happened’ and ‘why it happened’—capturing inputs, outputs, latencies, and failure modes to explain behavior post-deployment.”*\\n\\n✅ **Why this helps**: Makes the contrast more operational and less philosophical.\\n\\n---\\n\\n#### 3. **Add a Brief Comparison Table (Optional but Powerful)**  \\nWhile your prose is strong, a **simple 2-column table** in the middle or as a sidebar (if formatting allows) would make the contrast instantly digestible.\\n\\n| Feature | LangChain | LangSmith |\\n|--------|-----------|-----------|\\n| **Purpose** | Build LLM apps | Observe & optimize LLM apps |\\n| **Type** | Open-source framework | SaaS observability platform |\\n| **Key Tools** | Prompts, Chains, Agents, Tools | Tracing, Evaluation, A/B Testing, UI Dashboard |\\n| **Deployment** | Anywhere (local, cloud, on-prem) | Cloud-hosted (with SDK integration) |\\n| **Cost** | Free | Freemium (paid for teams/enterprise) |\\n| **Best For** | Prototyping, solo devs, open-source projects | Production scaling, teams, compliance, reliability |\\n\\n✅ **Why this helps**: Visual learners (including hiring managers and technical leads) will appreciate this. Even if you don’t include the table in the final text, writing it forces you to crystallize distinctions.\\n\\n---\\n\\n#### 4. **Strengthen the Conclusion with a Forward-Looking Statement**  \\n**Current conclusion**: Strong, but ends with a summary.  \\n**Recommendation**: Add one sentence projecting the future:  \\n> *“As LLM applications grow in complexity and regulatory scrutiny, the divide between development and observability will only widen—making the LangChain + LangSmith stack not just a best practice, but a de facto standard for responsible AI engineering.”*\\n\\n✅ **Why this helps**: Positions your essay not just as explanatory, but as predictive and authoritative.\\n\\n---\\n\\n#### 5. **Minor Stylistic Tweaks for Polish**\\n\\n| Original | Suggested Revision | Reason |\\n|--------|-------------------|--------|\\n| “LangSmith fills this gap by automatically capturing every step…” | “LangSmith fills this gap by **automatically logging and visualizing** every step…” | “Capturing” is passive; “logging and visualizing” is more precise and aligns with LangSmith’s actual features. |\\n| “...without touching the core application code.” | “...without modifying the core application code.” | “Touching” is informal; “modifying” is more professional. |\\n| “...form a complete lifecycle solution: LangChain for creation, LangSmith for confidence.” | “...form a complete AI lifecycle solution: LangChain for **construction**, LangSmith for **validation**.” | “Creation” is vague; “construction” fits engineering context. “Confidence” is abstract; “validation” is measurable and industry-standard. |\\n\\n---\\n\\n### 📏 **Length & Scope Recommendation**\\n\\nYour current essay is **~650 words**—perfect for a blog post or technical article.  \\nIf submitting for **academic or professional publication**, aim for **800–1,000 words** to fully incorporate the suggested enhancements (especially the real-world example and forward-looking statement).\\n\\n---\\n\\n### 🏆 Final Grade: **A+ (Excellent — Near Publication Ready)**\\n\\nWith the minor enhancements above, this piece could be published on:\\n- **LangChain’s official blog**\\n- **Towards Data Science**\\n- **The Gradient (or similar AI publications)**\\n- **Internal engineering docs at AI startups**\\n\\nYou’ve demonstrated not just technical fluency, but **architectural thinking**—the hallmark of a senior AI engineer.\\n\\n---\\n\\n### ✅ Final Checklist Before Submission\\n\\n- [ ] Added one concrete failure case (e.g., bias, hallucination, tool error)  \\n- [ ] Refined “what/why” contrast to be more operational  \\n- [ ] Considered adding a comparison table (optional but recommended)  \\n- [ ] Polished 2–3 phrases for formality/precision  \\n- [ ] Added forward-looking closing sentence  \\n- [ ] Word count: 800–1,000 (if targeting publication)\\n\\n---\\n\\nYou’ve written something that could help countless developers avoid the pitfalls of unobserved LLM systems. **Well done.** With these refinements, it becomes not just informative—but *influential*.'}}\n",
      "{'research_critique': {'content': ['In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', \"LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. You might think of LangSmith as LangChain's counterpart, but it takes things further by focusing on managing, debugging, and orchestrating AI and ML models. LangSmith steps in to give you the tools you need to debug and monitor your models at scale, ensuring everything is running as expected in your AI system. In short, while LangChain excels at managing and scaling model workflows, LangSmith is designed for when you need deep visibility and control over large, complex AI systems in production. If you're debugging complex AI models or managing large-scale workflows with multiple moving parts, LangSmith's advanced debugging and orchestration features will be indispensable.\", 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', '### LangChain: Building with Chains, Tools, and Prompts LangChain wraps this behavior into its agent classes, so you don’t have to build it from scratch, **but you still need to define the tools, prompt logic, and output parsers yourself**. Setting `verbose=True` as shown above shows the full prompt that LangChain constructs for the LLM, including tool names, usage instructions, and expected output format. And because every LLM evaluation is tied to a specific versioned prompt and function, you can trace patterns across iterations and app versions — something that’s harder to do in systems like LangSmith, where evaluations are often tied to static datasets or separated from prompt logic.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while **Langchain** excels at managing and scaling model workflows, **Langsmith** is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a **complex AI pipeline** with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, **Langsmith’s advanced debugging and orchestration features** will be indispensable. Additionally, if you’re working on **cross-platform model deployments** — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', '[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Da18cff9b31f0&operation=register&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=---header_actions--a18cff9b31f0---------------------post_audio_button------------------) [What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=---post_responses--a18cff9b31f0---------------------respond_sidebar------------------) [![Image 11: Ajay Verma](https://miro.medium.com/v2/resize:fill:20:20/1*bcWYlekM-dWdWA5Tp2whcg.jpeg)](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [Ajay Verma](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) While Generative AI has…](https://medium.com/@ajayverma23/from-ai-agents-to-agentic-ai-to-mcp-servers-revolutionizing-automation-and-decision-making-a5fb8ab710f4?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [35 3](https://medium.com/@ajayverma23/from-ai-agents-to-agentic-ai-to-mcp-servers-revolutionizing-automation-and-decision-making-a5fb8ab710f4?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 13: GoPenAI](https://miro.medium.com/v2/resize:fill:20:20/1*LUSEiP1BHPkkmH75e8eg_A.png)](https://blog.gopenai.com/?source=post_page---author_recirc--a18cff9b31f0----1---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 15: GoPenAI](https://miro.medium.com/v2/resize:fill:20:20/1*LUSEiP1BHPkkmH75e8eg_A.png)](https://blog.gopenai.com/?source=post_page---author_recirc--a18cff9b31f0----2---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 17: Ajay Verma](https://miro.medium.com/v2/resize:fill:20:20/1*bcWYlekM-dWdWA5Tp2whcg.jpeg)](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [Ajay Verma](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) Two of the most prominent frameworks for…](https://medium.com/@ajayverma23/google-adk-vs-langgraph-a-comprehensive-blog-guide-eaceeb89d583?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [](https://medium.com/@ajayverma23/google-adk-vs-langgraph-a-comprehensive-blog-guide-eaceeb89d583?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 19: James Tang](https://miro.medium.com/v2/resize:fill:20:20/1*vnM7rwphFHLaxFPoE4rokw.png)](https://medium.com/@jamestang?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [James Tang](https://medium.com/@jamestang?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [](https://medium.com/@jamestang/exploring-rag-retrieval-augmented-generation-with-python-1645ad66f765?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 21: Mothish](https://miro.medium.com/v2/resize:fill:20:20/1*FUlvx_kntiJu6H6iQklXaA.jpeg)](https://mothishdeenadayalan.medium.com/?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Mothish](https://mothishdeenadayalan.medium.com/?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) But here’s what nobody tells you upfront…](https://mothishdeenadayalan.medium.com/langchain-vs-langgraph-the-beginners-guide-15daa489c018?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [50](https://mothishdeenadayalan.medium.com/langchain-vs-langgraph-the-beginners-guide-15daa489c018?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 23: Towards AI](https://miro.medium.com/v2/resize:fill:20:20/1*JyIThO-cLjlChQLb6kSlVQ.png)](https://pub.towardsai.net/?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Sayanteka Chakraborty](https://medium.com/@sd24chakraborty?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 25: aakash](https://miro.medium.com/v2/resize:fill:20:20/1*wkAmsUU1Zshd-u9CxHxUxw.jpeg)](https://medium.com/@aakash_7?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [aakash](https://medium.com/@aakash_7?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [14 2](https://medium.com/@aakash_7/the-future-of-ai-prompting-5-context-levels-fc12d6fdf862?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 27: Artificial Intelligence in Plain English](https://miro.medium.com/v2/resize:fill:20:20/1*9zAmnK08gUCmZX7q0McVKw@2x.png)](https://ai.plainenglish.io/?source=post_page---read_next_recirc--a18cff9b31f0----2---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Piyush Agnihotri](https://medium.com/@piyushagni5?source=post_page---read_next_recirc--a18cff9b31f0----2---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc2c4578c836a&operation=register&redirect=https%3A%2F%2Fai.plainenglish.io%2Fbuilding-agentic-rag-with-langgraph-mastering-adaptive-rag-for-production-c2c4578c836a&source=---read_next_recirc--a18cff9b31f0----2-----------------bookmark_preview----bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 29: Sanjit Khasnobis](https://miro.medium.com/v2/resize:fill:20:20/1*gOxwJEpFDszNFJT_VrzO_g.jpeg)](https://medium.com/@khasnobis.sanjit890?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Sanjit Khasnobis](https://medium.com/@khasnobis.sanjit890?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Difference between lang Chain and Lang Graph: Land of Agentic AI ---------------------------------------------------------------- ### I always enjoy exploring both sides of my skill set — as an Engineer and as an Architect.](https://medium.com/@khasnobis.sanjit890/difference-between-lang-chain-and-lang-graph-land-of-agentic-ai-ff373240fa07?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [1](https://medium.com/@khasnobis.sanjit890/difference-between-lang-chain-and-lang-graph-land-of-agentic-ai-ff373240fa07?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------)', 'LLMs can also have a bias toward a value when asked to score given a range and they also prefer longer responses.', 'This lack of transparency can make it difficult for users to understand the decision-making process or ensure optimal performance when developing applications through LLMs. This article explores LangSmith, an all-in-one platform based on LangChain’s ecosystem for Tracing and Evaluating LLMs. LangSmith provides a comprehensive toolbox for assessing and evaluating LLMs’ workings and overall performance based on user-specific datasets, evaluation methods, and tasks. 6. Langsmith for Practical LLM Tracing and Evaluation ## Langsmith for Practical LLM Tracing and Evaluation Through the trace, we were able to understand the technical parameters and the execution flows, and the evaluator helped us find out if our LLM model was able to generate correct results or not. Using the tracing, evaluation tools, datasets and prompt playground users can understand, assess and improve their LLM operations easily and efficiently.', 'In LLM application development, LangChain and LangSmith have become central tools for building and managing large language model-powered solutions. This article compares LangChain and LangSmith, focusing on their core features, integration options, and value for developers in the LLM application space. **Overview:**LangChain is an open-source framework that helps developers create LLM applications efficiently. LangSmith provides tools to debug, monitor, and improve LLM-powered agents, and offers a managed cloud service with a web UI. | LLM Evaluation | Minimal built-in support; developers typically create custom logic or use external tools. LangChain provides building blocks for LLM applications, while LangSmith offers observability and evaluation. LangChain is open-source and free, while LangSmith follows a freemium model for managed services.', '[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=post_page---top_nav_layout_nav-----------------------global_nav------------------) [Listen](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Da18cff9b31f0&operation=register&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=---header_actions--a18cff9b31f0---------------------post_audio_button------------------) [What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fblog.gopenai.com%2Flangchain-vs-langsmith-understanding-the-differences-pros-and-cons-a18cff9b31f0&source=---post_responses--a18cff9b31f0---------------------respond_sidebar------------------) [![Image 11: Ajay Verma](https://miro.medium.com/v2/resize:fill:20:20/1*bcWYlekM-dWdWA5Tp2whcg.jpeg)](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [Ajay Verma](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) While Generative AI has…](https://medium.com/@ajayverma23/from-ai-agents-to-agentic-ai-to-mcp-servers-revolutionizing-automation-and-decision-making-a5fb8ab710f4?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [35 3](https://medium.com/@ajayverma23/from-ai-agents-to-agentic-ai-to-mcp-servers-revolutionizing-automation-and-decision-making-a5fb8ab710f4?source=post_page---author_recirc--a18cff9b31f0----0---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 13: GoPenAI](https://miro.medium.com/v2/resize:fill:20:20/1*LUSEiP1BHPkkmH75e8eg_A.png)](https://blog.gopenai.com/?source=post_page---author_recirc--a18cff9b31f0----1---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 15: GoPenAI](https://miro.medium.com/v2/resize:fill:20:20/1*LUSEiP1BHPkkmH75e8eg_A.png)](https://blog.gopenai.com/?source=post_page---author_recirc--a18cff9b31f0----2---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 17: Ajay Verma](https://miro.medium.com/v2/resize:fill:20:20/1*bcWYlekM-dWdWA5Tp2whcg.jpeg)](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [Ajay Verma](https://medium.com/@ajayverma23?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) Two of the most prominent frameworks for…](https://medium.com/@ajayverma23/google-adk-vs-langgraph-a-comprehensive-blog-guide-eaceeb89d583?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [](https://medium.com/@ajayverma23/google-adk-vs-langgraph-a-comprehensive-blog-guide-eaceeb89d583?source=post_page---author_recirc--a18cff9b31f0----3---------------------b40a7fc7_9aeb_443b_b7c1_e6c6d743aaa2--------------) [![Image 19: James Tang](https://miro.medium.com/v2/resize:fill:20:20/1*vnM7rwphFHLaxFPoE4rokw.png)](https://medium.com/@jamestang?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [James Tang](https://medium.com/@jamestang?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [](https://medium.com/@jamestang/exploring-rag-retrieval-augmented-generation-with-python-1645ad66f765?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 21: Mothish](https://miro.medium.com/v2/resize:fill:20:20/1*FUlvx_kntiJu6H6iQklXaA.jpeg)](https://mothishdeenadayalan.medium.com/?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Mothish](https://mothishdeenadayalan.medium.com/?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) But here’s what nobody tells you upfront…](https://mothishdeenadayalan.medium.com/langchain-vs-langgraph-the-beginners-guide-15daa489c018?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [50](https://mothishdeenadayalan.medium.com/langchain-vs-langgraph-the-beginners-guide-15daa489c018?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 23: Towards AI](https://miro.medium.com/v2/resize:fill:20:20/1*JyIThO-cLjlChQLb6kSlVQ.png)](https://pub.towardsai.net/?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Sayanteka Chakraborty](https://medium.com/@sd24chakraborty?source=post_page---read_next_recirc--a18cff9b31f0----0---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 25: aakash](https://miro.medium.com/v2/resize:fill:20:20/1*wkAmsUU1Zshd-u9CxHxUxw.jpeg)](https://medium.com/@aakash_7?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [aakash](https://medium.com/@aakash_7?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [14 2](https://medium.com/@aakash_7/the-future-of-ai-prompting-5-context-levels-fc12d6fdf862?source=post_page---read_next_recirc--a18cff9b31f0----1---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 27: Artificial Intelligence in Plain English](https://miro.medium.com/v2/resize:fill:20:20/1*9zAmnK08gUCmZX7q0McVKw@2x.png)](https://ai.plainenglish.io/?source=post_page---read_next_recirc--a18cff9b31f0----2---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Piyush Agnihotri](https://medium.com/@piyushagni5?source=post_page---read_next_recirc--a18cff9b31f0----2---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc2c4578c836a&operation=register&redirect=https%3A%2F%2Fai.plainenglish.io%2Fbuilding-agentic-rag-with-langgraph-mastering-adaptive-rag-for-production-c2c4578c836a&source=---read_next_recirc--a18cff9b31f0----2-----------------bookmark_preview----bd089f12_5430_48c9_84e3_09265cf28b74--------------) [![Image 29: Sanjit Khasnobis](https://miro.medium.com/v2/resize:fill:20:20/1*gOxwJEpFDszNFJT_VrzO_g.jpeg)](https://medium.com/@khasnobis.sanjit890?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Sanjit Khasnobis](https://medium.com/@khasnobis.sanjit890?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [Difference between lang Chain and Lang Graph: Land of Agentic AI ---------------------------------------------------------------- ### I always enjoy exploring both sides of my skill set — as an Engineer and as an Architect.](https://medium.com/@khasnobis.sanjit890/difference-between-lang-chain-and-lang-graph-land-of-agentic-ai-ff373240fa07?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------) [1](https://medium.com/@khasnobis.sanjit890/difference-between-lang-chain-and-lang-graph-land-of-agentic-ai-ff373240fa07?source=post_page---read_next_recirc--a18cff9b31f0----3---------------------bd089f12_5430_48c9_84e3_09265cf28b74--------------)', \"LLM observability is a systematic approach to gaining visibility into language models' behavior, performance, and outputs through comprehensive monitoring and analysis techniques. Tools like Galileo support observable architecture implementation by providing specialized monitoring frameworks for LLM applications. Through comprehensive LLM observability capabilities, you can detect anomalies in model behavior, track drift in response patterns, and receive notifications when outputs deviate from expected quality thresholds—all while maintaining visibility across your entire LLM stack for rapid incident resolution. Galileo simplifies this comprehensive approach with integrated LLM observability tools spanning the entire LLM lifecycle—from initial prompt engineering during development, through rigorous testing in staging, to production monitoring capturing both technical metrics and user interaction quality, all within a unified platform enabling continuous improvement.\", 'LLM observability is essential for ensuring large language models perform reliably in CI/CD workflows. * **Automated Testing**: Evaluate quality, performance, safety, and cost during CI/CD deployments. By integrating these practices with tools like Latitude, teams can improve LLM performance and ensure smooth deployments. Automated observability testing evaluates how LLMs perform throughout the CI/CD lifecycle, helping identify potential issues before they reach production. By implementing automated testing, teams can integrate observability seamlessly into CI/CD workflows using the right tools and platforms. Modern tools simplify LLM observability with features like real-time dashboards, version control, automated alerts, and team collaboration options. LLM observability in CI/CD pipelines is becoming a cornerstone for reliable monitoring, maintaining performance, and ensuring data protection.']}}\n",
      "{'generate': {'draft': '**The Difference Between LangChain and LangSmith: Building vs. Observing LLM Applications**\\n\\nIn the rapidly evolving landscape of large language model (LLM) application development, two tools have emerged as indispensable: LangChain and LangSmith. While they are often used together and are deeply integrated within the same ecosystem, their core purposes are fundamentally distinct. LangChain is an open-source framework designed to help developers *build* LLM-powered applications by providing modular components—such as prompts, chains, agents, and memory—to orchestrate complex workflows. LangSmith, on the other hand, is a managed cloud platform built to *observe, debug, and evaluate* those applications once they are deployed. In essence, LangChain is the construction kit; LangSmith is the control room. Developers use LangChain to assemble intelligent systems, and LangSmith to ensure those systems perform reliably, consistently, and transparently in production.\\n\\nLangChain’s strength lies in its flexibility and extensibility as a development framework. It abstracts away much of the boilerplate required to connect LLMs with external tools, databases, and APIs, enabling developers to create agents that can reason, plan, and act using prompts, tools, and memory. For example, a developer might use LangChain to build a customer support agent that retrieves documents from a vector store, generates responses using GPT-4, and logs interactions in a database—all with a few lines of Python code. However, LangChain provides minimal built-in observability. While setting `verbose=True` can reveal prompt inputs and intermediate steps during development, it offers no centralized logging, version control for prompts, or automated evaluation metrics. Developers must implement their own tracking, testing, and monitoring systems, which can become unwieldy as applications scale.\\n\\nLangSmith fills this critical gap by offering end-to-end observability for LLM applications. It automatically traces every step of an LLM workflow—including prompts, tool calls, model responses, and latency—creating a detailed, searchable audit trail accessible via a clean web UI. This is invaluable when debugging why a model produced an incorrect output: Was it a flawed prompt? A misconfigured tool? A drift in model behavior? LangSmith also enables developers to create and run evaluations against custom datasets, compare model versions side-by-side, and measure performance against ground-truth answers using predefined or custom metrics. Unlike LangChain, which is free and self-hosted, LangSmith operates on a freemium model, offering advanced features like team collaboration, CI/CD integration, and real-time alerts that are essential for production-grade systems. It transforms the opaque “black box” of LLMs into a transparent, measurable, and improvable system.\\n\\nThe synergy between the two tools is where their true power emerges. LangChain developers can instrument their applications with just a few lines of code to send traces to LangSmith, enabling immediate visibility into real-world usage without rewriting logic. For instance, a team building a research assistant with LangChain can use LangSmith to monitor how often the agent retrieves outdated documents, how user feedback correlates with response quality, or whether a newly tuned prompt improves accuracy across 1,000 test cases. This integration allows for rapid iteration: fix a prompt in development, test it in LangSmith’s playground, deploy it, and instantly compare its performance against the previous version. LangSmith’s support for cross-platform deployments—whether models run on-prem, in AWS, or on Azure—further ensures consistent monitoring across hybrid environments, a necessity for enterprise teams.\\n\\nIn summary, LangChain and LangSmith are not competitors but complementary pillars of modern LLM development. LangChain empowers developers to *create* sophisticated, dynamic LLM applications with minimal friction, while LangSmith ensures those applications *work as intended* in production. If you’re prototyping a chatbot or building a simple RAG pipeline, LangChain alone may suffice. But if you’re managing complex, multi-model workflows, scaling to thousands of users, or deploying across environments, LangSmith becomes indispensable for maintaining quality, accountability, and continuous improvement. Choosing between them isn’t a binary decision—it’s about recognizing that building an LLM app is only half the battle; understanding and refining it is the other. Together, they form the complete lifecycle toolkit for reliable, production-ready AI systems.', 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for s in graph.stream({\n",
    "    \"task\": \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "    \"plan\": \"\",\n",
    "    \"draft\": \"\",\n",
    "    \"critique\": \"\",\n",
    "    \"content\": [] \n",
    "}, thread\n",
    "):\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_experimental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
